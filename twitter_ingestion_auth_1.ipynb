{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5567deb2-678e-469f-b2fb-ddd67b7feff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SouthwestAir\n",
      "2022-8-15_HOUR-0_@SouthwestAir\n",
      "#southwestairlines\n",
      "2022-8-15_HOUR-0_#southwestairlines\n",
      "#southwestairline\n",
      "API error!\n",
      "API error!\n",
      "2022-8-15_HOUR-0_#southwestairline\n",
      "#airlines\n",
      "2022-8-15_HOUR-0_#airlines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_blobs(bucket_name, folder_name):\n",
    "    gcs_client = storage.Client()\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blobs = list(bucket.list_blobs(prefix=folder_name))\n",
    "    names = []\n",
    "    for b in blobs: names.append(b.name)\n",
    "    return names\n",
    "\n",
    "def upload_to_output(path, bucket_name, folder_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(folder_name + '/' + path.split('/')[-1])\n",
    "    blob.upload_from_filename(path)\n",
    "    \n",
    "def stack_tweets(new_records, existing_records):\n",
    "    captured_tokens = list(existing_records.id.unique())\n",
    "    response_tokens = list(new_records.id.unique())\n",
    "    already_captured = [x for x in response_tokens if x in captured_tokens]\n",
    "    \n",
    "    x = len(captured_tokens)\n",
    "    y = len(response_tokens)\n",
    "    z = len(already_captured)\n",
    "    \n",
    "    existing_records = existing_records.append(new_records)\n",
    "    \n",
    "    print('Existing tokens: ', x, 'Response tokens: ', y, 'Already_captured: ', z, 'Efficiency Rate: ', str(round(z/y,2)*100)+'%')\n",
    "    return existing_records\n",
    "\n",
    "def searchRTOfTweetIDQuery(tweet_id):\n",
    "    return 'retweets_of_tweet_id:'+str(tweet_id)\n",
    "\n",
    "    \n",
    "class TwitterAPI():\n",
    "    def __init__(self, bearer_token, consumer_key, consumer_secret, access_token, access_token_secret):\n",
    "        import requests\n",
    "        self.client = tweepy.Client( bearer_token=bearer_token, \n",
    "                        consumer_key=consumer_key, \n",
    "                        consumer_secret=consumer_secret, \n",
    "                        access_token=access_token, \n",
    "                        access_token_secret=access_token_secret, \n",
    "                        return_type = requests.Response,\n",
    "                        wait_on_rate_limit=True)\n",
    "        \n",
    "        \n",
    "        self.results = {}\n",
    "        \n",
    "    def get_tweets(self, keyword, max_results):\n",
    "        query = keyword\n",
    "        from datetime import datetime\n",
    "        ts = str(datetime.now())\n",
    "        reference_id = ts+'__'+keyword\n",
    "        if max_results <= 100:\n",
    "            tweets = self.client.search_recent_tweets(query=query, \n",
    "                                                tweet_fields=['id', 'author_id', 'conversation_id', 'in_reply_to_user_id', 'created_at', 'text', 'public_metrics'],\n",
    "                                                 max_results=max_results)\n",
    "            tweets_dict = tweets.json() \n",
    "            tweets_data = tweets_dict['data'] \n",
    "            df = pd.json_normalize(tweets_data)\n",
    "            df = df.set_index('id')\n",
    "\n",
    "            self.results[reference_id] = df\n",
    "\n",
    "            return df\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            count = 0\n",
    "            done = False\n",
    "            \n",
    "            tweets = self.client.search_recent_tweets(query=query, \n",
    "                                                    tweet_fields=['id', 'author_id', 'conversation_id', 'in_reply_to_user_id', 'created_at', 'text', 'public_metrics'],\n",
    "                                                     max_results=100)\n",
    "            tweets_dict = tweets.json() \n",
    "            tweets_data = tweets_dict['data'] \n",
    "            df = pd.json_normalize(tweets_data)\n",
    "            existing_records = df.set_index('id')\n",
    "            \n",
    "            count = len(df)\n",
    "            \n",
    "            while not done:\n",
    "                \n",
    "                tweets = self.client.search_recent_tweets(query=query, \n",
    "                                                    tweet_fields=['id', 'author_id', 'conversation_id', 'in_reply_to_user_id', 'created_at', 'text', 'public_metrics'],\n",
    "                                                     max_results=100)\n",
    "                tweets_dict = tweets.json() \n",
    "                tweets_data = tweets_dict['data'] \n",
    "                new_records = pd.json_normalize(tweets_data)\n",
    "                new_records = df.set_index('id')\n",
    "\n",
    "                x = len(existing_records)\n",
    "                y = len(new_records)\n",
    "\n",
    "                existing_records = existing_records.append(new_records, ignore_index=False)\n",
    "                \n",
    "                added = len(existing_records) - x\n",
    "                \n",
    "                eff = round(added/y,2)\n",
    "                \n",
    "                # print('Existing tokens: ', x, 'Response tokens: ', y, 'Already_captured: ', y-added, 'Efficiency Rate: ', str(eff*100)+'%')\n",
    "                \n",
    "                count+=added\n",
    "                \n",
    "                done = count >= max_results\n",
    "                \n",
    "            df = existing_records\n",
    "            self.results[reference_id] = df\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def aggregate_results(self):\n",
    "        searches = list(self.results.keys())\n",
    "\n",
    "        src = []\n",
    "        for x in searches:\n",
    "            src.append(api.results[x])\n",
    "\n",
    "        results = pd.concat(src, ignore_index=False)\n",
    "        \n",
    "        return results.copy()\n",
    "\n",
    "    \n",
    "# IMPORT STATEMENTS\n",
    "try: import tweepy\n",
    "except ModuleNotFoundError: \n",
    "    os.system('pip install tweepy')\n",
    "    import tweepy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# SCRIPT CONSTANTS\n",
    "MAX_HOUR_LIMIT = 500\n",
    "KEYWORDS = ['@SouthwestAir', '#southwestairlines', '#southwestairline', '#airlines']\n",
    "AUTHENTICATION_COUNT = 1\n",
    "MAX_RESULT_PULL = AUTHENTICATION_COUNT*MAX_HOUR_LIMIT/len(KEYWORDS)\n",
    "\n",
    "# How to connect to cloud storage\n",
    "from google.cloud import storage\n",
    "\n",
    "# Instantiates a client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# The name for the new bucket\n",
    "bucket_name = \"sw-airlines-data-hub\"\n",
    "\n",
    "# Creates the new bucket\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SET TIME LABEL\n",
    "from datetime import datetime\n",
    "currentDateAndTime = datetime.now()\n",
    "timeLabel = ''\n",
    "timeLabel+=str(currentDateAndTime.year) + '-' \n",
    "timeLabel+= str(currentDateAndTime.month) + '-' \n",
    "timeLabel+=str(currentDateAndTime.day) + '_HOUR-' \n",
    "timeLabel+=str(currentDateAndTime.hour)\n",
    "\n",
    "\n",
    "# IF YOU GET MORE THAN 1 AUTH\n",
    "consumer_key = \"afxygKWvjyHeYqK2VOudagVF5\"\n",
    "consumer_secret = \"s3aiZTpaWJXsqkqzxdhetnGaXSoXyJo5fay0PvaRbe7azGUTdB\"\n",
    "access_token = \"133488849-J5PyZGIBiWaZ91gd4EaL9Ni0yaCeUUeevA3pUk3j\"\n",
    "access_token_secret = \"39wEmtno1NucvjkT5GrBupwQstmHaPukj3KRFZj48EW31\"\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAANgJegEAAAAA7apqttgkq4Do4dGRoxfB0MD6D6w%3DGTFCK7VJJjA4fR0d0k9XCsrV6h7D36pmLyq6g5Vmnw9ZtZxT7k\"\n",
    "\n",
    "auth1 = {'consumer_key':consumer_key,\n",
    "'consumer_secret':consumer_secret,\n",
    "'access_token' : access_token,\n",
    "'access_token_secret' : access_token_secret,\n",
    "'bearer_token' : bearer_token} \n",
    "\n",
    "# consumer_key = '1r00ftJDzKTcaLCGgb0WWlCak'\n",
    "# consumer_secret = 'ligckZVYi8ygX0Rs4HhcVMjnQ0NB3vFG8cG9QMQXyFWei1sO2X'\n",
    "# access_token = '1547339723798093829-2w6gIpXLZf2953rkyZbbN95dkQcs55'\n",
    "# access_token_secret = 'RUSGsMrqpJIeKbQhCGn5DwAZDpV4EAgxZvudKrQRhXkq6'\n",
    "# bearer_token = 'AAAAAAAAAAAAAAAAAAAAAG7lfwEAAAAAn3AnJpgxBjK2FmzPlulBSH8440U%3DEiB4dx0ggR5GnRZqmgDS6oHd8iqD58dDAqfLzZAV7tZWNBfRHX'\n",
    "\n",
    "# auth2 = {'consumer_key':consumer_key,\n",
    "# 'consumer_secret':consumer_secret,\n",
    "# 'access_token' : access_token,\n",
    "# 'access_token_secret' : access_token_secret,\n",
    "# 'bearer_token' : bearer_token} \n",
    "\n",
    "auths = [auth1]\n",
    "apis = []\n",
    "\n",
    "for creds in auths:\n",
    "    apis.append(TwitterAPI(creds['bearer_token'], \n",
    "                           creds['consumer_key'], \n",
    "                           creds['consumer_secret'], \n",
    "                           creds['access_token'], \n",
    "                           creds['access_token_secret']))\n",
    "\n",
    "first = True\n",
    "for k in KEYWORDS:\n",
    "    query=''\n",
    "    query = k + ' -is:retweet'\n",
    "    print(k)\n",
    "    for api in apis:\n",
    "        try:\n",
    "            if first:\n",
    "                df = api.get_tweets(query, 100)\n",
    "                first = False\n",
    "            else:\n",
    "                df2 = api.get_tweets(query, 100)\n",
    "                df = df.append(df2, ignore_index=False)\n",
    "        except:\n",
    "            print('API error!')\n",
    "\n",
    "    file_label = timeLabel + '_' + k + '.csv'\n",
    "\n",
    "    local_path = file_label\n",
    "    df.to_csv(local_path)\n",
    "    \n",
    "    upload_to_output(local_path, bucket_name, 'data/source')\n",
    "    print(local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d70c9-a6cf-428f-a378-8da91e637e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
