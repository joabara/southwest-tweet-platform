{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Network Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289,
     "referenced_widgets": [
      "7822ba54600c4b98a2c1384e807cf7f2",
      "48c6d7a4deea4cb0952f9734c5a12de0",
      "806f53121eef4a6bb30bb4cad5521dc1",
      "5ba701494c4d48b2a9b766c51b798f58",
      "f7b941d2da12456d8fa89f1405503593",
      "73cd4ea92d014eeebb2d4b9f37fa58bd",
      "75fe23d12672468297cb7f6603170ecd",
      "60e81752589e4f3989e76d17c20cc724",
      "0427795af8c3400fb8bbe86242d67c00",
      "1e6e690505ba42688665d5e739e172f6",
      "d3a7bc8c194e4ddbb96cbdd857e7e5a5",
      "8726e1e579944d6dba5dacb9052bf3dd",
      "6e609e7182254c318b9eeaa6f9a7a75e",
      "26e61edc0e444750ac1043ed33dee198",
      "9fc496389b434edfb97ea294d818940b",
      "6708795febeb43d18233912bf67e0bd2",
      "7a38a068872c4927b5fea0c0c6f4f351",
      "34f70d50033c4c508769c18170fb304f",
      "c6c8a3d854b3413fa1c860c8cfc18582",
      "74a5798d9f3d4b9d98c9c1a85b60b088",
      "a3993e76242a4d04bf4c62f04869ada0",
      "b45d3925ee8b4f4396cadbffad536bf6"
     ]
    },
    "id": "sk3UacRoYd4O",
    "outputId": "268e00cb-ada4-4a8e-a604-3af24cb3daa1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.64.1)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk) (4.11.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.8.1)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.7 regex-2022.10.31\n",
      "Collecting stanza\n",
      "  Using cached stanza-1.4.2-py3-none-any.whl (691 kB)\n",
      "Requirement already satisfied: torch>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from stanza) (1.12.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from stanza) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from stanza) (4.64.1)\n",
      "Requirement already satisfied: protobuf in ./.local/lib/python3.7/site-packages (from stanza) (3.19.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from stanza) (1.21.6)\n",
      "Collecting emoji\n",
      "  Using cached emoji-2.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.3.0->stanza) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->stanza) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->stanza) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->stanza) (1.26.11)\n",
      "Installing collected packages: emoji, stanza\n",
      "Successfully installed emoji-2.2.0 stanza-1.4.2\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.7/site-packages (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: 193kB [00:00, 49.0MB/s]                    \n",
      "2022-11-25 16:46:22 INFO: Downloading default packages for language: en (English) ...\n",
      "2022-11-25 16:46:28 INFO: File exists: /home/jupyter/stanza_resources/en/default.zip\n",
      "2022-11-25 16:46:37 INFO: Finished downloading models and saved to /home/jupyter/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system('pip install nltk')\n",
    "os.system('pip install stanza')\n",
    "os.system('pip install emoji')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "import stanza\n",
    "stanza.download(\"en\")\n",
    "\n",
    "class Tweet():\n",
    "    def __init__(self, text, text_clean, token, author_id):\n",
    "        self.token = token\n",
    "        self.text = text\n",
    "        self.text_clean = text_clean\n",
    "        self.author_id = author_id\n",
    "        \n",
    "        self.similiar_tweets = []\n",
    "        self.similiar_authors = []\n",
    "\n",
    "        self.sentiments = {}\n",
    "        self.associations = []\n",
    "\n",
    "class User():\n",
    "    def __init__(self, author_id):\n",
    "        self.author_id = author_id\n",
    "        self.tweet_tokens = []\n",
    "        self.similiar_authors = []\n",
    "        self.author_edges = {}\n",
    "\n",
    "#Removing Emojis\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "                      u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                      u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                      u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                      u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                      u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                      u\"\\U00002702-\\U000027B0\"\n",
    "                      u\"\\U00002702-\\U000027B0\"\n",
    "                      u\"\\U000024C2-\\U0001F251\"\n",
    "                      u\"\\U0001f926-\\U0001f937\"\n",
    "                      u\"\\U00010000-\\U0010ffff\"\n",
    "                      u\"\\u2640-\\u2642\"\n",
    "                      u\"\\u2600-\\u2B55\"\n",
    "                      u\"\\u200d\"\n",
    "                      u\"\\u23cf\"\n",
    "                      u\"\\u23e9\"\n",
    "                      u\"\\u231a\"\n",
    "                      u\"\\ufe0f\"  # dingbats\n",
    "                      u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', str(data))\n",
    "\n",
    "def cleaner(text):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",str(text)) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", str(text)) #Remove http links\n",
    "    tweet = re.sub('[()!?]', ' ', str(text)) #removing punctuation\n",
    "    tweet = re.sub('\\[.*?\\]',' ', str(text))\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(str(text))\n",
    "                     if w.lower() in words or not w.isalpha())\n",
    "    return text\n",
    "\n",
    "def calculate_sentiments(text, stop_words, nlp):\n",
    "    txt = text\n",
    "    sentList = nltk.sent_tokenize(txt) # Splitting the text into sentences\n",
    "    fcluster = []\n",
    "    totalfeatureList = []\n",
    "    finalcluster = []\n",
    "    featureList = []\n",
    "    categories = []\n",
    "    dic = {}\n",
    "\n",
    "    for line in sentList:\n",
    "        # Remove links from line\n",
    "        line = re.sub(r'http\\S+|#', '', line)\n",
    "\n",
    "        # Swap '-', ';', '*' with commas\n",
    "        line = re.sub(':', '.', line)\n",
    "        line = re.sub('\\n|@', '', line)\n",
    "\n",
    "        # Remove consecutive punctuation recursively\n",
    "        r = re.compile(r'([.,/#!$%^&*;:{}=_`~()-])[.,/#!$%^&*;:{}=_`~()-]+')\n",
    "        line = r.sub(r'\\1', line)\n",
    "\n",
    "        # Replace hashtags with association term\n",
    "        line = re.sub('#', 'hashtag is ', line)\n",
    "\n",
    "        try:\n",
    "            newtaggedList = []\n",
    "            txt_list = nltk.word_tokenize(line) # Splitting up into words\n",
    "            taggedList = nltk.pos_tag(txt_list) # Doing Part-of-Speech Tagging to each word\n",
    "\n",
    "            newwordList = []\n",
    "            flag = 0\n",
    "            for i in range(0,len(taggedList)-1):\n",
    "                if(taggedList[i][1]==\"NN\" and taggedList[i+1][1]==\"NN\"): # If two consecutive words are Nouns then they are joined together\n",
    "                    newwordList.append(taggedList[i][0]+taggedList[i+1][0])\n",
    "                    flag=1\n",
    "                else:\n",
    "                    if(flag==1):\n",
    "                        flag=0\n",
    "                        continue\n",
    "                    newwordList.append(taggedList[i][0])\n",
    "                    if(i==len(taggedList)-2):\n",
    "                        newwordList.append(taggedList[i+1][0])\n",
    "\n",
    "            finaltxt = ' '.join(word for word in newwordList)\n",
    "            new_txt_list = nltk.word_tokenize(finaltxt)\n",
    "            wordsList = [w for w in new_txt_list if not w in stop_words]\n",
    "            taggedList = nltk.pos_tag(wordsList)\n",
    "\n",
    "            doc = nlp(finaltxt) # Object of Stanford NLP Pipeleine\n",
    "\n",
    "            dep_node = []\n",
    "\n",
    "            for dep_edge in doc.sentences[0].dependencies:\n",
    "                dep_node.append([dep_edge[2].text, dep_edge[0].id, dep_edge[1]])\n",
    "\n",
    "            for i in range(0, len(dep_node)):\n",
    "                if (int(dep_node[i][1]) != 0):\n",
    "                    dep_node[i][1] = newwordList[(int(dep_node[i][1]) - 1)]\n",
    "\n",
    "            # featureList = []\n",
    "            # categories = []\n",
    "            for i in taggedList:\n",
    "                if(i[1]=='JJ' or i[1]=='NN' or i[1]=='JJR' or i[1]=='NNS' or i[1]=='RB'):\n",
    "                    featureList.append(list(i))\n",
    "                    totalfeatureList.append(list(i)) # This list will store all the features for every sentence\n",
    "                    categories.append(i[0])\n",
    "\n",
    "            for i in featureList:\n",
    "                filist = []\n",
    "                for j in dep_node:\n",
    "                    if((j[0]==i[0] or j[1]==i[0]) and (j[2] in [\"nsubj\", \"acl:relcl\", \"obj\", \"dobj\", \"agent\", \"advmod\", \"amod\", \"neg\", \"prep_of\", \"acomp\", \"xcomp\", \"compound\"])):\n",
    "                        if(j[0]==i[0]):\n",
    "                            filist.append(j[1])\n",
    "                        else:\n",
    "                            filist.append(j[0])\n",
    "                fcluster.append([i[0], filist])\n",
    "\n",
    "        except IndexError:\n",
    "            print('IndexError:', line)\n",
    "            return []\n",
    "\n",
    "        except AttributeError:\n",
    "            print('AttributeError')\n",
    "            return []\n",
    "\n",
    "    for i in featureList:\n",
    "        dic[i[0]] = i[1]\n",
    "\n",
    "    for i in fcluster:\n",
    "        if(dic[i[0]]==\"NN\"):\n",
    "            finalcluster.append(i)\n",
    "\n",
    "    return finalcluster\n",
    "\n",
    "def upload_to_output(path, bucket_name, folder_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(folder_name + '/' + path.split('/')[-1])\n",
    "    blob.upload_from_filename(path)\n",
    "\n",
    "from google.cloud import storage   \n",
    "bucket_name = 'sw-airlines-data-hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQ_ykyMfZAkY",
    "outputId": "f317b31b-042f-4720-db93-c8a794918484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book 4665\n",
      "cancel 3675\n",
      "call 2793\n",
      "support 969\n",
      "delay 4676\n",
      "change 1984\n",
      "never 2772\n",
      "fear 2590\n",
      "pandemic 534\n",
      "group 1657\n",
      "pilot 4768\n",
      "mask 737\n",
      "avgeek 5994\n",
      "technology 337\n",
      "pay 2530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>...</th>\n",
       "      <th>description</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>profile_image_url</th>\n",
       "      <th>username</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>user.following_count</th>\n",
       "      <th>user.tweet_count</th>\n",
       "      <th>user.listed_count</th>\n",
       "      <th>withheld.country_codes_y</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-11-08T15:07:29.000Z</td>\n",
       "      <td>7212562.0</td>\n",
       "      <td>['1589998047110782976']</td>\n",
       "      <td>@SouthwestAir Thanks, I'll do that now :)</td>\n",
       "      <td>790555820</td>\n",
       "      <td>1589997663336148993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-08-30T01:35:58.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/155849327...</td>\n",
       "      <td>NickChaps96</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>7026.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>southwestair thanks ill do that now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-08T15:05:58.000Z</td>\n",
       "      <td>7212562.0</td>\n",
       "      <td>['1589997663336148993']</td>\n",
       "      <td>@SouthwestAir we have a flight from Norfolk to...</td>\n",
       "      <td>790555820</td>\n",
       "      <td>1589997663336148993</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-08-30T01:35:58.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/155849327...</td>\n",
       "      <td>NickChaps96</td>\n",
       "      <td>325.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>7026.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>southwestair we have a flight from norfolk to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-08T15:03:16.000Z</td>\n",
       "      <td>14179945.0</td>\n",
       "      <td>['1589996983066189824']</td>\n",
       "      <td>@AviatorJLat @EGAinMA @SouthwestAir @USDOT @No...</td>\n",
       "      <td>28853549</td>\n",
       "      <td>1589787523353833474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Nerd. Fangirl. Campaigning to #SaveDaredevil s...</td>\n",
       "      <td>2009-04-04T19:27:59.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/126807649...</td>\n",
       "      <td>catzmiaou</td>\n",
       "      <td>556.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aviatorjlat egainma southwestair usdot nonuttr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-11-08T15:03:16.000Z</td>\n",
       "      <td>14179945.0</td>\n",
       "      <td>['1589996983066189824']</td>\n",
       "      <td>@AviatorJLat @EGAinMA @SouthwestAir @USDOT @No...</td>\n",
       "      <td>28853549</td>\n",
       "      <td>1589787523353833474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Nerd. Fangirl. Campaigning to #SaveDaredevil s...</td>\n",
       "      <td>2009-04-04T19:27:59.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/126807649...</td>\n",
       "      <td>catzmiaou</td>\n",
       "      <td>556.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aviatorjlat egainma southwestair usdot nonuttr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-11-08T15:01:41.000Z</td>\n",
       "      <td>16271858.0</td>\n",
       "      <td>['1589996585316147200']</td>\n",
       "      <td>@kaoconnor @SouthwestAir @DENAirport @MidwayAi...</td>\n",
       "      <td>1198826459147554816</td>\n",
       "      <td>1589305162308329472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Advocating for basic decency and social graces...</td>\n",
       "      <td>2019-11-25T04:51:25.000Z</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/119882696...</td>\n",
       "      <td>twit_traveling</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kaoconnor southwestair denairport midwayairpor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              created_at_x  in_reply_to_user_id  \\\n",
       "0           0  2022-11-08T15:07:29.000Z            7212562.0   \n",
       "1           1  2022-11-08T15:05:58.000Z            7212562.0   \n",
       "2           2  2022-11-08T15:03:16.000Z           14179945.0   \n",
       "3           3  2022-11-08T15:03:16.000Z           14179945.0   \n",
       "4           4  2022-11-08T15:01:41.000Z           16271858.0   \n",
       "\n",
       "    edit_history_tweet_ids                                               text  \\\n",
       "0  ['1589998047110782976']          @SouthwestAir Thanks, I'll do that now :)   \n",
       "1  ['1589997663336148993']  @SouthwestAir we have a flight from Norfolk to...   \n",
       "2  ['1589996983066189824']  @AviatorJLat @EGAinMA @SouthwestAir @USDOT @No...   \n",
       "3  ['1589996983066189824']  @AviatorJLat @EGAinMA @SouthwestAir @USDOT @No...   \n",
       "4  ['1589996585316147200']  @kaoconnor @SouthwestAir @DENAirport @MidwayAi...   \n",
       "\n",
       "             author_id      conversation_id  public_metrics.retweet_count  \\\n",
       "0            790555820  1589997663336148993                             0   \n",
       "1            790555820  1589997663336148993                             0   \n",
       "2             28853549  1589787523353833474                             0   \n",
       "3             28853549  1589787523353833474                             0   \n",
       "4  1198826459147554816  1589305162308329472                             0   \n",
       "\n",
       "   public_metrics.reply_count  public_metrics.like_count  ...  \\\n",
       "0                           0                          0  ...   \n",
       "1                           1                          0  ...   \n",
       "2                           0                          0  ...   \n",
       "3                           0                          0  ...   \n",
       "4                           0                          0  ...   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  Nerd. Fangirl. Campaigning to #SaveDaredevil s...   \n",
       "3  Nerd. Fangirl. Campaigning to #SaveDaredevil s...   \n",
       "4  Advocating for basic decency and social graces...   \n",
       "\n",
       "               created_at_y  \\\n",
       "0  2012-08-30T01:35:58.000Z   \n",
       "1  2012-08-30T01:35:58.000Z   \n",
       "2  2009-04-04T19:27:59.000Z   \n",
       "3  2009-04-04T19:27:59.000Z   \n",
       "4  2019-11-25T04:51:25.000Z   \n",
       "\n",
       "                                   profile_image_url        username  \\\n",
       "0  https://pbs.twimg.com/profile_images/155849327...     NickChaps96   \n",
       "1  https://pbs.twimg.com/profile_images/155849327...     NickChaps96   \n",
       "2  https://pbs.twimg.com/profile_images/126807649...       catzmiaou   \n",
       "3  https://pbs.twimg.com/profile_images/126807649...       catzmiaou   \n",
       "4  https://pbs.twimg.com/profile_images/119882696...  twit_traveling   \n",
       "\n",
       "  user.followers_count user.following_count user.tweet_count  \\\n",
       "0                325.0               1594.0           7026.0   \n",
       "1                325.0               1594.0           7026.0   \n",
       "2                556.0                492.0           7200.0   \n",
       "3                556.0                492.0           7200.0   \n",
       "4                  0.0                  0.0             76.0   \n",
       "\n",
       "  user.listed_count withheld.country_codes_y  \\\n",
       "0               6.0                      NaN   \n",
       "1               6.0                      NaN   \n",
       "2               6.0                      NaN   \n",
       "3               6.0                      NaN   \n",
       "4               0.0                      NaN   \n",
       "\n",
       "                                         tweet_clean  \n",
       "0               southwestair thanks ill do that now   \n",
       "1  southwestair we have a flight from norfolk to ...  \n",
       "2  aviatorjlat egainma southwestair usdot nonuttr...  \n",
       "3  aviatorjlat egainma southwestair usdot nonuttr...  \n",
       "4  kaoconnor southwestair denairport midwayairpor...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('gs://sw-airlines-data-hub/data/processed/sw-airlines-tweets-w-users.csv')\n",
    "df['tweet_clean'] = df['text'].str.lower().str.replace(r'[^0-9a-zA-Z\\s]+', '', regex=True).apply(cleaner)\n",
    "df['tweet_clean'] = df['tweet_clean'].apply(remove_emojis)\n",
    "X = df[['text', 'tweet_clean', 'tweet_token', 'author_id']]\n",
    "X.head()\n",
    "\n",
    "topics = ['book', 'cancel', 'call', 'support', 'delay', 'change', 'never', 'fear',\n",
    "          'pandemic', 'group', 'pilot', 'mask', 'avgeek', 'technology', 'pay']\n",
    "dfs = []\n",
    "\n",
    "for t in topics:\n",
    "    dfs.append(X[X.tweet_clean.str.contains(t)])\n",
    "    print(t, len(X[X.tweet_clean.str.contains(t)]))\n",
    "\n",
    "x0 = pd.concat(dfs)\n",
    "x0 = x0.set_index('tweet_token')\n",
    "x0['tweet_token'] = x0.index\n",
    "x0 = x0[['tweet_token', 'author_id', 'tweet_clean']]\n",
    "x0 = x0.drop_duplicates(\n",
    "  subset = ['tweet_clean'],\n",
    "  keep = 'first').reset_index(drop = True)\n",
    "lx0 = len(x0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://sw-airlines-data-hub/data/processed/twt2twt_w_score_w_sentiments.pkl...\n",
      "| [1 files][ 64.6 MiB/ 64.6 MiB]                                                \n",
      "Operation completed over 1 objects/64.6 MiB.                                     \n",
      "Copying gs://sw-airlines-data-hub/data/processed/auth2auth.pkl...\n",
      "/ [1 files][  8.2 MiB/  8.2 MiB]                                                \n",
      "Operation completed over 1 objects/8.2 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Import tweet 2 tweet, author to author pickles\n",
    "!gsutil cp gs://sw-airlines-data-hub/data/processed/twt2twt_w_score_w_sentiments.pkl ./\n",
    "!gsutil cp gs://sw-airlines-data-hub/data/processed/auth2auth.pkl ./\n",
    "\n",
    "import pickle\n",
    "with open('twt2twt_w_score_w_sentiments.pkl', 'rb') as f:\n",
    "    tweet_objs = pickle.load(f)\n",
    "    \n",
    "with open('auth2auth_w_score.pkl', 'rb') as f:\n",
    "    auth_objs = pickle.load(f)\n",
    "\n",
    "tweets = {} \n",
    "for x in tweet_objs: tweets[x.token] = x\n",
    "tweet_tokens = [x.token for x in tweet_objs]\n",
    "\n",
    "authors = {} \n",
    "for x in auth_objs: authors[x.author_id] = x\n",
    "unique_authors = [x.author_id for x in auth_objs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweet_tokens[3]].associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t2t = pd.DataFrame(columns = ['TweetTokenA', 'TweetTokenB', 'SimilarityScore', 'AspectsA', 'AspectsB'])\n",
    "\n",
    "for x in tweet_tokens:\n",
    "    for j in tweets[x].similiar_tweets:\n",
    "        t2t.loc[len(t2t)] = [x, j[0], j[1], str(tweets[x].associations), str(tweets[j[0]].associations)]\n",
    "\n",
    "t2t = t2t.drop_duplicates()        \n",
    "\n",
    "a_comp = df[['tweet_token', 'author_id', 'username', 'text', 'created_at_x', 'public_metrics.retweet_count',\n",
    " 'public_metrics.reply_count',\n",
    " 'public_metrics.like_count',\n",
    " 'public_metrics.quote_count']]\n",
    "\n",
    "t2t = t2t.merge(a_comp, left_on='TweetTokenA', right_on='tweet_token')\n",
    "t2t = t2t.rename(columns={'author_id': 'AuthorTokenA', \n",
    "                          'username' : 'UserA', \n",
    "                          'text_clean' : 'A_text_clean', \n",
    "                          'created_at_x' : 'A_created_at', \n",
    "                          'public_metrics.retweet_count' : 'A_rt_cnt',\n",
    "                          'public_metrics.reply_count' : 'A_reply_cnt',\n",
    "                          'public_metrics.like_count' : 'A_like_count',\n",
    "                          'public_metrics.quote_count' : 'A_qt_count'})\n",
    "t2t = t2t.drop(columns=['tweet_token'])\n",
    "\n",
    "t2t = t2t.merge(a_comp, left_on='TweetTokenB', right_on='tweet_token')\n",
    "t2t = t2t.rename(columns={'author_id': 'AuthorTokenB', \n",
    "                          'username' : 'UserB', \n",
    "                          'text_clean':'B_text_clean', \n",
    "                          'created_at_x':'b_created_at', \n",
    "                          'public_metrics.retweet_count':'B_rt_cnt',\n",
    "                          'public_metrics.reply_count':'B_reply_cnt',\n",
    "                          'public_metrics.like_count':'B_like_count',\n",
    "                          'public_metrics.quote_count':'B_qt_count'})\n",
    "t2t = t2t.drop(columns=['tweet_token'])\n",
    "t2t = t2t.drop_duplicates(subset = ['TweetTokenA', 'TweetTokenB'],  keep = 'first')\n",
    "t2t = t2t[t2t.TweetTokenA!=t2t.TweetTokenB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2t.to_pickle('tweet2tweet_df3_pre.pickle')\n",
    "def upload_to_output(path, bucket_name, folder_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(folder_name + '/' + path.split('/')[-1])\n",
    "    blob.upload_from_filename(path)\n",
    "\n",
    "from google.cloud import storage   \n",
    "bucket_name = 'sw-airlines-data-hub'\n",
    "upload_to_output('tweet2tweet_df3_pre.pickle', bucket_name, 'data/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://sw-airlines-data-hub/data/processed/tweet2tweet_df3_pre.pickle ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2t = pd.read_pickle('tweet2tweet_df3_pre.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = list(t2t.index)\n",
    "kill_list = []\n",
    "\n",
    "for x in search_list:\n",
    "    a_token = t2t.loc[x].TweetTokenA \n",
    "    b_token = t2t.loc[x].TweetTokenB\n",
    "    a = t2t[t2t.TweetTokenB == a_token]\n",
    "    b = a[a.TweetTokenA==b_token]\n",
    "    i = b.index.values[0]\n",
    "    kill_list.append(i)\n",
    "    search_list.remove(i)\n",
    "\n",
    "t2t = t2t.drop(index = kill_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2t = t2t.fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dedupe measure\n",
    "t2t.to_pickle('tweet2tweet_df3.pickle')\n",
    "upload_to_output('tweet2tweet_df3.pickle', bucket_name, 'data/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3\n",
    "\n",
    "for q in unique_authors: authors[q].similiar_authors = [*set(authors[q].similiar_authors)]\n",
    "test_run = intersection(unique_authors, [tweets[x].author_id for x in tweet_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 36s, sys: 720 ms, total: 52min 36s\n",
      "Wall time: 52min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a2a = pd.DataFrame(columns = ['AuthorTokenA', 'AuthorTokenB', 'MeanSimilarity_Score', 'NumEdges', 'NumMutualSimiliarTweets', \n",
    "                              'NumTweetsA', 'NumTweetsB', 'NumTweetsCombined']) \n",
    "                   \n",
    "for x in unique_authors:\n",
    "    author_a = authors[x]   \n",
    "    \n",
    "    for j in author_a.similiar_authors:           \n",
    "        num_edges = 0      \n",
    "        author_b = authors[j]\n",
    "                   \n",
    "        a_tweets = author_a.tweet_tokens\n",
    "        tweets_similiar_to_a = []\n",
    "        for at in a_tweets: tweets_similiar_to_a += tweets[at].similiar_tweets\n",
    "        \n",
    "        b_tweets = author_b.tweet_tokens\n",
    "        tweets_similiar_to_b = []\n",
    "        for bt in b_tweets: tweets_similiar_to_b += tweets[bt].similiar_tweets\n",
    "        \n",
    "        a_similiar_tokens = [x[0] for x in tweets_similiar_to_a]\n",
    "        b_similiar_tokens = [x[0] for x in tweets_similiar_to_b]\n",
    "        \n",
    "        # only look at tweets in between two authors\n",
    "        intertweets = intersection(a_similiar_tokens + b_similiar_tokens, a_tweets + b_tweets)\n",
    "        a_intertweets = intersection(a_tweets, intertweets)\n",
    "        b_intertweets = intersection(b_tweets, intertweets)\n",
    "        \n",
    "        edge_weights = []\n",
    "        \n",
    "        for i in a_intertweets:\n",
    "            edge_weights += [x[1] for x in tweets[i].similiar_tweets if x[0] in b_intertweets]\n",
    "            \n",
    "        if len(edge_weights) > 0: average_edge_weight = sum(edge_weights) / len(edge_weights)\n",
    "        else: average_edge_weight = 0\n",
    "            \n",
    "        num_edges = len(intersection(a_similiar_tokens, b_tweets))\n",
    "        numMutualSimiliarTweets = len(intersection(a_similiar_tokens, b_similiar_tokens))\n",
    "                        \n",
    "        a2a.loc[len(a2a)] = [author_a.author_id, author_b.author_id, average_edge_weight, num_edges, numMutualSimiliarTweets, \n",
    "                             len(a_tweets), len(b_tweets), len(a_tweets)+len(b_tweets)]   \n",
    "\n",
    "a2a = a2a.drop_duplicates(subset = ['AuthorTokenA', 'AuthorTokenB'],  keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2a = a2a.fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_comp = df[['author_id', 'username', 'verified', 'profile_image_url', 'description']]\n",
    "a2a = a2a.merge(a_comp, left_on='AuthorTokenA', right_on='author_id')\n",
    "a2a = a2a.rename(columns={'username' : 'UserA', 'verified':'A_is_verified', 'profile_image_url': 'A_prof_img_url', 'description' : 'A_description'})\n",
    "a2a = a2a.drop(columns=['author_id'])\n",
    "\n",
    "a2a = a2a.merge(a_comp, left_on='AuthorTokenB', right_on='author_id')\n",
    "a2a = a2a.rename(columns={'username' : 'UserB', 'verified':'B_is_verified', 'profile_image_url': 'B_prof_img_url', 'description' : 'B_description'})\n",
    "a2a = a2a.drop(columns=['author_id'])\n",
    "a2a = a2a.drop_duplicates(subset = ['AuthorTokenA', 'AuthorTokenB'],  keep = 'first')\n",
    "a2a = a2a[a2a.AuthorTokenA!=a2a.AuthorTokenB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = list(a2a.index)\n",
    "kill_list = []\n",
    "\n",
    "for x in search_list:\n",
    "    a_token = a2a.loc[x].AuthorTokenA \n",
    "    b_token = a2a.loc[x].AuthorTokenB\n",
    "    a = a2a[a2a.AuthorTokenB == a_token]\n",
    "    b = a[a.AuthorTokenA==b_token]\n",
    "    i = b.index.values[0]\n",
    "    kill_list.append(i)\n",
    "    search_list.remove(i)\n",
    "\n",
    "a2a = a2a.drop(index = kill_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 ms, sys: 11 ¬µs, total: 26.9 ms\n",
      "Wall time: 57.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a2a.to_pickle('author2author_df3.pickle') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorTokenA</th>\n",
       "      <th>AuthorTokenB</th>\n",
       "      <th>MeanSimilarity_Score</th>\n",
       "      <th>NumEdges</th>\n",
       "      <th>NumMutualSimiliarTweets</th>\n",
       "      <th>NumTweetsA</th>\n",
       "      <th>NumTweetsB</th>\n",
       "      <th>NumTweetsCombined</th>\n",
       "      <th>UserA</th>\n",
       "      <th>a_is_verified</th>\n",
       "      <th>a_prof_img_url</th>\n",
       "      <th>a_description</th>\n",
       "      <th>UserB</th>\n",
       "      <th>b_is_verified</th>\n",
       "      <th>b_prof_img_url</th>\n",
       "      <th>b_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.091670e+09</td>\n",
       "      <td>4.299009e+09</td>\n",
       "      <td>0.881317</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>comedianarthur</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/157486347...</td>\n",
       "      <td>YHTBH podcast out everywhere every Monday. Hou...</td>\n",
       "      <td>hippie_79</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/156065396...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.941071e+07</td>\n",
       "      <td>4.299009e+09</td>\n",
       "      <td>0.890870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cthacker1987</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/121387058...</td>\n",
       "      <td>Just me!</td>\n",
       "      <td>hippie_79</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/156065396...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.137970e+09</td>\n",
       "      <td>4.299009e+09</td>\n",
       "      <td>0.887860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>darkALLYE</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/151716589...</td>\n",
       "      <td>Marketer. Baker. Photographer. Liberty and Fre...</td>\n",
       "      <td>hippie_79</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/156065396...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.912859e+07</td>\n",
       "      <td>4.299009e+09</td>\n",
       "      <td>0.884027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>itsbrookielou</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/147883697...</td>\n",
       "      <td>Vegas Born. üíô Ella. üê∂</td>\n",
       "      <td>hippie_79</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/156065396...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.559754e+18</td>\n",
       "      <td>4.299009e+09</td>\n",
       "      <td>0.881764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OrtizOrosa3445</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/155975400...</td>\n",
       "      <td>God does.</td>\n",
       "      <td>hippie_79</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/156065396...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56157476</th>\n",
       "      <td>1.781722e+07</td>\n",
       "      <td>7.682630e+17</td>\n",
       "      <td>0.893968</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>mamatoria</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/464763219...</td>\n",
       "      <td>educator, proud Pirate mom, unbelievably grate...</td>\n",
       "      <td>VintageloverH</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/140673640...</td>\n",
       "      <td>Recovering lawyer. I teach Constitutional Law ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56157639</th>\n",
       "      <td>2.249620e+08</td>\n",
       "      <td>1.874799e+09</td>\n",
       "      <td>0.985652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yespunjab</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/127970296...</td>\n",
       "      <td>https://t.co/Hfj7lUJJPV #News #Entertainment #...</td>\n",
       "      <td>TheHansIndiaWeb</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/119325921...</td>\n",
       "      <td>The Hans India is a leading English news paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56158411</th>\n",
       "      <td>2.709679e+09</td>\n",
       "      <td>4.000142e+08</td>\n",
       "      <td>0.995655</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Fexcogroup</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154396956...</td>\n",
       "      <td>A World Leader In Innovative #FinTech, #Paymen...</td>\n",
       "      <td>FexcoDCC</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/985612987...</td>\n",
       "      <td>Fexco is the originator of Dynamic Currency Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56158741</th>\n",
       "      <td>3.783896e+07</td>\n",
       "      <td>1.170733e+18</td>\n",
       "      <td>0.889373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>jfrankk13</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/152954816...</td>\n",
       "      <td>She/her. I take photos sometimes - https://t.c...</td>\n",
       "      <td>desecratedhost</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/147273498...</td>\n",
       "      <td>saw girlboyfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56159587</th>\n",
       "      <td>8.931113e+17</td>\n",
       "      <td>1.565037e+18</td>\n",
       "      <td>0.929818</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Lazycrrow</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/156562926...</td>\n",
       "      <td>üå† | Rest is rust and stardust..\\nüë®‚Äçüíª | Busines...</td>\n",
       "      <td>yadavmamta18</td>\n",
       "      <td>False</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/157154645...</td>\n",
       "      <td>#Contest #F4F\\n#ContestLover\\n#stufflistingsarmy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23842 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AuthorTokenA  AuthorTokenB  MeanSimilarity_Score  NumEdges  \\\n",
       "0         3.091670e+09  4.299009e+09              0.881317       2.0   \n",
       "3         3.941071e+07  4.299009e+09              0.890870       1.0   \n",
       "6         1.137970e+09  4.299009e+09              0.887860       1.0   \n",
       "10        3.912859e+07  4.299009e+09              0.884027       1.0   \n",
       "13        1.559754e+18  4.299009e+09              0.881764       1.0   \n",
       "...                ...           ...                   ...       ...   \n",
       "56157476  1.781722e+07  7.682630e+17              0.893968       2.0   \n",
       "56157639  2.249620e+08  1.874799e+09              0.985652       1.0   \n",
       "56158411  2.709679e+09  4.000142e+08              0.995655       6.0   \n",
       "56158741  3.783896e+07  1.170733e+18              0.889373       1.0   \n",
       "56159587  8.931113e+17  1.565037e+18              0.929818       2.0   \n",
       "\n",
       "          NumMutualSimiliarTweets  NumTweetsA  NumTweetsB  NumTweetsCombined  \\\n",
       "0                             4.0         3.0         1.0                4.0   \n",
       "3                             3.0         3.0         1.0                4.0   \n",
       "6                             4.0         4.0         1.0                5.0   \n",
       "10                            4.0         1.0         1.0                2.0   \n",
       "13                            2.0         1.0         1.0                2.0   \n",
       "...                           ...         ...         ...                ...   \n",
       "56157476                      3.0         1.0         2.0                3.0   \n",
       "56157639                      2.0         1.0         1.0                2.0   \n",
       "56158411                     12.0         6.0         2.0                8.0   \n",
       "56158741                      2.0         1.0         3.0                4.0   \n",
       "56159587                      4.0         2.0         2.0                4.0   \n",
       "\n",
       "                   UserA a_is_verified  \\\n",
       "0         comedianarthur         False   \n",
       "3           Cthacker1987         False   \n",
       "6              darkALLYE         False   \n",
       "10         itsbrookielou         False   \n",
       "13        OrtizOrosa3445         False   \n",
       "...                  ...           ...   \n",
       "56157476       mamatoria         False   \n",
       "56157639       yespunjab         False   \n",
       "56158411      Fexcogroup         False   \n",
       "56158741       jfrankk13         False   \n",
       "56159587       Lazycrrow         False   \n",
       "\n",
       "                                             a_prof_img_url  \\\n",
       "0         https://pbs.twimg.com/profile_images/157486347...   \n",
       "3         https://pbs.twimg.com/profile_images/121387058...   \n",
       "6         https://pbs.twimg.com/profile_images/151716589...   \n",
       "10        https://pbs.twimg.com/profile_images/147883697...   \n",
       "13        https://pbs.twimg.com/profile_images/155975400...   \n",
       "...                                                     ...   \n",
       "56157476  https://pbs.twimg.com/profile_images/464763219...   \n",
       "56157639  https://pbs.twimg.com/profile_images/127970296...   \n",
       "56158411  https://pbs.twimg.com/profile_images/154396956...   \n",
       "56158741  https://pbs.twimg.com/profile_images/152954816...   \n",
       "56159587  https://pbs.twimg.com/profile_images/156562926...   \n",
       "\n",
       "                                              a_description            UserB  \\\n",
       "0         YHTBH podcast out everywhere every Monday. Hou...        hippie_79   \n",
       "3                                                  Just me!        hippie_79   \n",
       "6         Marketer. Baker. Photographer. Liberty and Fre...        hippie_79   \n",
       "10                                    Vegas Born. üíô Ella. üê∂        hippie_79   \n",
       "13                                                God does.        hippie_79   \n",
       "...                                                     ...              ...   \n",
       "56157476  educator, proud Pirate mom, unbelievably grate...    VintageloverH   \n",
       "56157639  https://t.co/Hfj7lUJJPV #News #Entertainment #...  TheHansIndiaWeb   \n",
       "56158411  A World Leader In Innovative #FinTech, #Paymen...         FexcoDCC   \n",
       "56158741  She/her. I take photos sometimes - https://t.c...   desecratedhost   \n",
       "56159587  üå† | Rest is rust and stardust..\\nüë®‚Äçüíª | Busines...     yadavmamta18   \n",
       "\n",
       "         b_is_verified                                     b_prof_img_url  \\\n",
       "0                False  https://pbs.twimg.com/profile_images/156065396...   \n",
       "3                False  https://pbs.twimg.com/profile_images/156065396...   \n",
       "6                False  https://pbs.twimg.com/profile_images/156065396...   \n",
       "10               False  https://pbs.twimg.com/profile_images/156065396...   \n",
       "13               False  https://pbs.twimg.com/profile_images/156065396...   \n",
       "...                ...                                                ...   \n",
       "56157476         False  https://pbs.twimg.com/profile_images/140673640...   \n",
       "56157639         False  https://pbs.twimg.com/profile_images/119325921...   \n",
       "56158411         False  https://pbs.twimg.com/profile_images/985612987...   \n",
       "56158741         False  https://pbs.twimg.com/profile_images/147273498...   \n",
       "56159587         False  https://pbs.twimg.com/profile_images/157154645...   \n",
       "\n",
       "                                              b_description  \n",
       "0                                                       NaN  \n",
       "3                                                       NaN  \n",
       "6                                                       NaN  \n",
       "10                                                      NaN  \n",
       "13                                                      NaN  \n",
       "...                                                     ...  \n",
       "56157476  Recovering lawyer. I teach Constitutional Law ...  \n",
       "56157639  The Hans India is a leading English news paper...  \n",
       "56158411  Fexco is the originator of Dynamic Currency Co...  \n",
       "56158741                                  saw girlboyfriend  \n",
       "56159587   #Contest #F4F\\n#ContestLover\\n#stufflistingsarmy  \n",
       "\n",
       "[23842 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_to_output('author2author_df3.pickle', bucket_name, 'data/processed')\n",
    "a2a"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Pytorch (Local)",
   "language": "python",
   "name": "local-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0427795af8c3400fb8bbe86242d67c00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e6e690505ba42688665d5e739e172f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26e61edc0e444750ac1043ed33dee198": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6c8a3d854b3413fa1c860c8cfc18582",
      "max": 561333907,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74a5798d9f3d4b9d98c9c1a85b60b088",
      "value": 561333907
     }
    },
    "34f70d50033c4c508769c18170fb304f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48c6d7a4deea4cb0952f9734c5a12de0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73cd4ea92d014eeebb2d4b9f37fa58bd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_75fe23d12672468297cb7f6603170ecd",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: "
     }
    },
    "5ba701494c4d48b2a9b766c51b798f58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e6e690505ba42688665d5e739e172f6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d3a7bc8c194e4ddbb96cbdd857e7e5a5",
      "value": " 193k/? [00:00&lt;00:00, 2.63MB/s]"
     }
    },
    "60e81752589e4f3989e76d17c20cc724": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6708795febeb43d18233912bf67e0bd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e609e7182254c318b9eeaa6f9a7a75e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a38a068872c4927b5fea0c0c6f4f351",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_34f70d50033c4c508769c18170fb304f",
      "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/default.zip: 100%"
     }
    },
    "73cd4ea92d014eeebb2d4b9f37fa58bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74a5798d9f3d4b9d98c9c1a85b60b088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "75fe23d12672468297cb7f6603170ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7822ba54600c4b98a2c1384e807cf7f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48c6d7a4deea4cb0952f9734c5a12de0",
       "IPY_MODEL_806f53121eef4a6bb30bb4cad5521dc1",
       "IPY_MODEL_5ba701494c4d48b2a9b766c51b798f58"
      ],
      "layout": "IPY_MODEL_f7b941d2da12456d8fa89f1405503593"
     }
    },
    "7a38a068872c4927b5fea0c0c6f4f351": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "806f53121eef4a6bb30bb4cad5521dc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60e81752589e4f3989e76d17c20cc724",
      "max": 28918,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0427795af8c3400fb8bbe86242d67c00",
      "value": 28918
     }
    },
    "8726e1e579944d6dba5dacb9052bf3dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e609e7182254c318b9eeaa6f9a7a75e",
       "IPY_MODEL_26e61edc0e444750ac1043ed33dee198",
       "IPY_MODEL_9fc496389b434edfb97ea294d818940b"
      ],
      "layout": "IPY_MODEL_6708795febeb43d18233912bf67e0bd2"
     }
    },
    "9fc496389b434edfb97ea294d818940b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3993e76242a4d04bf4c62f04869ada0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b45d3925ee8b4f4396cadbffad536bf6",
      "value": " 561M/561M [00:02&lt;00:00, 250MB/s]"
     }
    },
    "a3993e76242a4d04bf4c62f04869ada0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b45d3925ee8b4f4396cadbffad536bf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6c8a3d854b3413fa1c860c8cfc18582": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3a7bc8c194e4ddbb96cbdd857e7e5a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7b941d2da12456d8fa89f1405503593": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
