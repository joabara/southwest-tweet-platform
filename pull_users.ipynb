{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aac470c-932a-43be-a628-d0969e25e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "        \n",
    "def get_blobs(bucket_name, folder_name):\n",
    "    gcs_client = storage.Client()\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blobs = list(bucket.list_blobs(prefix=folder_name))\n",
    "    names = []\n",
    "    for b in blobs: names.append(b.name)\n",
    "    return names\n",
    "\n",
    "def upload_to_output(path, bucket_name, folder_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(folder_name + '/' + path.split('/')[-1])\n",
    "    blob.upload_from_filename(path)\n",
    "    \n",
    "def stack_tweets(new_records, existing_records):\n",
    "    captured_tokens = list(existing_records.id.unique())\n",
    "    response_tokens = list(new_records.id.unique())\n",
    "    already_captured = [x for x in response_tokens if x in captured_tokens]\n",
    "    \n",
    "    x = len(captured_tokens)\n",
    "    y = len(response_tokens)\n",
    "    z = len(already_captured)\n",
    "    \n",
    "    existing_records = existing_records.append(new_records, ignore_index=False)\n",
    "    \n",
    "    print('Existing tokens: ', x, 'Response tokens: ', y,\n",
    "          'Already_captured: ', z, 'Efficiency Rate: ', str(round(z/y,2)*100)+'%')\n",
    "    return existing_records\n",
    "\n",
    "def searchRTOfTweetIDQuery(tweet_id):\n",
    "    return 'retweets_of_tweet_id:'+str(tweet_id)\n",
    "\n",
    "    \n",
    "class TwitterAPI():\n",
    "    def __init__(self, bearer_token, consumer_key, consumer_secret, access_token, access_token_secret):\n",
    "        import requests\n",
    "        self.client = tweepy.Client( bearer_token=bearer_token, \n",
    "                        consumer_key=consumer_key, \n",
    "                        consumer_secret=consumer_secret, \n",
    "                        access_token=access_token, \n",
    "                        access_token_secret=access_token_secret, \n",
    "                        return_type = requests.Response,\n",
    "                        wait_on_rate_limit=True)\n",
    "        \n",
    "        \n",
    "        self.results = {}\n",
    "        \n",
    "    def get_tweets(self, keyword, max_results):\n",
    "        query = keyword\n",
    "        from datetime import datetime\n",
    "        ts = str(datetime.now())\n",
    "        reference_id = ts+'__'+keyword\n",
    "        if max_results <= 100:\n",
    "            tweets = self.client.search_recent_tweets(query=query, \n",
    "                                                tweet_fields=['id', 'author_id', 'conversation_id',\n",
    "                                                              'in_reply_to_user_id', 'created_at',\n",
    "                                                              'text', 'public_metrics'],\n",
    "                                                 max_results=max_results)\n",
    "            tweets_dict = tweets.json() \n",
    "            tweets_data = tweets_dict['data'] \n",
    "            df = pd.json_normalize(tweets_data)\n",
    "            df = df.set_index('id')\n",
    "\n",
    "            self.results[reference_id] = df\n",
    "\n",
    "            return df\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            count = 0\n",
    "            done = False\n",
    "            \n",
    "            tweets = self.client.search_recent_tweets(query=query, \n",
    "                                                    tweet_fields=['id', 'author_id', 'conversation_id',\n",
    "                                                                  'in_reply_to_user_id', 'created_at',\n",
    "                                                                  'text', 'public_metrics'],\n",
    "                                                     max_results=100)\n",
    "            tweets_dict = tweets.json() \n",
    "            tweets_data = tweets_dict['data'] \n",
    "            df = pd.json_normalize(tweets_data)\n",
    "            existing_records = df.set_index('id')\n",
    "            \n",
    "            count = len(df)\n",
    "            \n",
    "            while not done:\n",
    "                \n",
    "                tweets = self.client.search_recent_tweets(query=query, \n",
    "                                                    tweet_fields=['id', 'author_id', 'conversation_id',\n",
    "                                                                  'in_reply_to_user_id', 'created_at',\n",
    "                                                                  'text', 'public_metrics'],\n",
    "                                                     max_results=100)\n",
    "                tweets_dict = tweets.json() \n",
    "                tweets_data = tweets_dict['data'] \n",
    "                new_records = pd.json_normalize(tweets_data)\n",
    "                new_records = df.set_index('id')\n",
    "\n",
    "                x = len(existing_records)\n",
    "                y = len(new_records)\n",
    "\n",
    "                existing_records = existing_records.append(new_records, ignore_index=False)\n",
    "                \n",
    "                added = len(existing_records) - x\n",
    "                \n",
    "                eff = round(added/y,2)\n",
    "                \n",
    "                print('Existing tokens: ', x, 'Response tokens: ', y, 'Already_captured: ',\n",
    "                      y-added, 'Efficiency Rate: ', str(eff*100)+'%')\n",
    "                \n",
    "                count+=added\n",
    "                \n",
    "                done = count >= max_results\n",
    "                \n",
    "            df = existing_records\n",
    "            self.results[reference_id] = df\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def aggregate_results(self):\n",
    "        searches = list(self.results.keys())\n",
    "\n",
    "        src = []\n",
    "        for x in searches:\n",
    "            src.append(api.results[x])\n",
    "\n",
    "        results = pd.concat(src, ignore_index=False)\n",
    "        \n",
    "        return results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ba1728-d8e2-41f6-bf36-cc39d6e727e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.11.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib<4,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (3.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.27.0->tweepy) (3.3)\n",
      "Installing collected packages: tweepy\n",
      "Successfully installed tweepy-4.11.0\n"
     ]
    }
   ],
   "source": [
    "# Create Twitter API Client\n",
    "import os\n",
    "\n",
    "try: import tweepy\n",
    "except ModuleNotFoundError: \n",
    "    !pip install tweepy\n",
    "    import tweepy\n",
    "    \n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 280\n",
    "\n",
    "\n",
    "# consumer_key = '1r00ftJDzKTcaLCGgb0WWlCak'\n",
    "# consumer_secret = 'ligckZVYi8ygX0Rs4HhcVMjnQ0NB3vFG8cG9QMQXyFWei1sO2X'\n",
    "# access_token = '1547339723798093829-2w6gIpXLZf2953rkyZbbN95dkQcs55'\n",
    "# access_token_secret = 'RUSGsMrqpJIeKbQhCGn5DwAZDpV4EAgxZvudKrQRhXkq6'\n",
    "# bearer_token = 'AAAAAAAAAAAAAAAAAAAAAG7lfwEAAAAAn3AnJpgxBjK2FmzPlulBSH8440U%3DEiB4dx0ggR5GnRZqmgDS6oHd8iqD58dDAqfLzZAV7tZWNBfRHX'\n",
    "\n",
    "consumer_key = \"afxygKWvjyHeYqK2VOudagVF5\"\n",
    "consumer_secret = \"s3aiZTpaWJXsqkqzxdhetnGaXSoXyJo5fay0PvaRbe7azGUTdB\"\n",
    "access_token = \"133488849-J5PyZGIBiWaZ91gd4EaL9Ni0yaCeUUeevA3pUk3j\"\n",
    "access_token_secret = \"39wEmtno1NucvjkT5GrBupwQstmHaPukj3KRFZj48EW31\"\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAANgJegEAAAAA7apqttgkq4Do4dGRoxfB0MD6D6w%3DGTFCK7VJJjA4fR0d0k9XCsrV6h7D36pmLyq6g5Vmnw9ZtZxT7k\"\n",
    "\n",
    "creds = {'consumer_key':consumer_key,\n",
    "'consumer_secret':consumer_secret,\n",
    "'access_token' : access_token,\n",
    "'access_token_secret' : access_token_secret,\n",
    "'bearer_token' : bearer_token} \n",
    "\n",
    "api = TwitterAPI(creds['bearer_token'], \n",
    "                       creds['consumer_key'], \n",
    "                       creds['consumer_secret'], \n",
    "                       creds['access_token'], \n",
    "                       creds['access_token_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d1cdca-e5ad-4cc5-8301-e73aaddc4ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5693"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIRST RUN - CREATE USER TABLE\n",
    "import pandas as pd\n",
    "df = pd.read_csv('gs://sw-airlines-data-hub/data/processed/sw-airlines-tweets-base.csv')\n",
    "user_df = pd.read_csv('gs://sw-airlines-data-hub/data/users/user_id.csv')\n",
    "user_df = user_df.set_index('id')\n",
    "recorded_users = list(user_df.index.unique())\n",
    "\n",
    "user_id = df.drop(columns=['id', 'text', 'conversation_id','created_at',\n",
    "                           'in_reply_to_user_id','public_metrics.retweet_count',\n",
    "                           'public_metrics.reply_count','public_metrics.like_count','public_metrics.quote_count'])\n",
    "user_id = user_id.set_index('author_id')\n",
    "user_id.to_csv('gs://sw-airlines-data-hub/data/src/author_id.csv')\n",
    "user_list = list(df.author_id.unique())\n",
    "new_users = [x for x in user_list if x not in recorded_users]\n",
    "len(new_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98fe00f3-b1e1-47a6-b72e-be568cabe863",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5693\n",
      "5594\n",
      "5495\n",
      "5396\n",
      "5297\n",
      "5198\n",
      "5099\n",
      "5000\n",
      "4901\n",
      "4802\n",
      "4703\n",
      "4604\n",
      "4505\n",
      "4406\n",
      "4307\n",
      "4208\n",
      "4109\n",
      "4010\n",
      "3911\n",
      "3812\n",
      "3713\n",
      "3614\n",
      "3515\n",
      "3416\n",
      "3317\n",
      "3218\n",
      "3119\n",
      "3020\n",
      "2921\n",
      "2822\n",
      "2723\n",
      "2624\n",
      "2525\n",
      "2426\n",
      "2327\n",
      "2228\n",
      "2129\n",
      "2030\n",
      "1931\n",
      "1832\n",
      "1733\n",
      "1634\n",
      "1535\n",
      "1436\n",
      "1337\n",
      "1238\n",
      "1139\n",
      "1040\n",
      "941\n",
      "842\n",
      "743\n",
      "644\n",
      "545\n",
      "446\n",
      "347\n",
      "248\n",
      "149\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "if len(new_users) > 0:\n",
    "    stack = []\n",
    "    dfs = []\n",
    "\n",
    "    while user_list and len(new_users) > 0:\n",
    "        time.sleep(3)\n",
    "        print(len(new_users))\n",
    "        while len(stack) < 99 and new_users:\n",
    "            stack.append(new_users.pop())\n",
    "        users = api.client.get_users(ids=list(stack), user_fields = ['id',\n",
    "                                                                     'username', \n",
    "                                                                     'profile_image_url', \n",
    "                                                                     'verified', \n",
    "                                                                     'description', \n",
    "                                                                     'created_at', \n",
    "                                                                     'public_metrics'])\n",
    "        try:\n",
    "            user_dict = users.json() \n",
    "            user_data = user_dict['data'] \n",
    "            df = pd.json_normalize(user_data)\n",
    "            dfs.append(df)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        stack = []\n",
    "\n",
    "    result = dfs.pop()\n",
    "    result = result.set_index('id')\n",
    "\n",
    "    for x in dfs: \n",
    "        x = x.set_index('id')\n",
    "        result = result.append(x, ignore_index=False)\n",
    "    user_df = user_df.append(result, ignore_index=False)\n",
    "    os.system('mkdir data')\n",
    "    user_df.to_csv('./data/user_id.csv')\n",
    "    from google.cloud import storage\n",
    "    storage_client = storage.Client()\n",
    "    bucket_name='sw-airlines-data-hub'\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    upload_to_output(path='data/user_id.csv', bucket_name=bucket_name, folder_name='data/users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d59ecb-e62a-45de-922b-60334029ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dfs.pop()\n",
    "result = result.set_index('id')\n",
    "for x in dfs: \n",
    "    x = x.set_index('id')\n",
    "    result = result.append(x, ignore_index=False)\n",
    "user_df = user_df.append(result, ignore_index=False)\n",
    "user_df.to_csv('data/user_id.csv')\n",
    "from google.cloud import storage\n",
    "storage_client = storage.Client()\n",
    "bucket_name='sw-airlines-data-hub'\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "upload_to_output(path='data/user_id.csv', bucket_name=bucket_name, folder_name='data/users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3e84c-19ec-45b9-8940-d6a171f4a764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c675f01-7222-46d4-8e50-0cf4bb175542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
